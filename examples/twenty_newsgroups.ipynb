{
 "metadata": {
  "name": "",
  "signature": "sha256:50bd710a160251f5961c3180db4ce2e8668ff14baebd97e70634fe2b689aba06"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Kitchen and 20 newsgroups dataset\n",
      "=================================\n",
      "\n",
      "This example illustrates how to train kitchen neural network using the standart 20 newsgroups dataset in a similiar way to the sklearn's tutorial: http://scikit-learn.org/stable/datasets/twenty_newsgroups.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import kitchen\n",
      "import lasagne"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Network architecture\n",
      "--------------------\n",
      "\n",
      "The network architecture is specified using Python class definition. kitchen uses multiple inheritance to specify a generic network structure (`kitchen.Network`), a training algorithm (`kitchen.SGDNesterovMomentum`), an optimization criterion (`kitchen.CategoricalCrossentropy`) and optionaly the regularization (`kitchen.L2Regularization`).\n",
      "\n",
      "create_layers()\n",
      "---------------\n",
      "\n",
      "The core method for specifying the network architecture is the `create_layers()` method. It's header looks like:\n",
      "\n",
      "    def create_layers(self, X_dim, y_dim, random_state):\n",
      "\n",
      "where:\n",
      "* `self` is self :-)\n",
      "* `X_dim` is the dimensionality of an input feature vector\n",
      "* `y_dim` is the dimensionality of an output target vector\n",
      "* `random_state` is a random state used to initialize network parameters\n",
      "\n",
      "The goal of the `create_layers()` method is to construct the layers the neural network and return tuple `(input_layer, output_layer)`.\n",
      "\n",
      "### Input layer\n",
      "\n",
      "To create the input layer instantiate the `lasagne.layers.InputLayer` class and use the `X_dim` parameter to determine the size of an input vector.\n",
      "\n",
      "### Output layer\n",
      "\n",
      "The ouput layer is the instance of any lasagne layer. To correctly train the network, it is necessary to match the optimization criterion and the output layer activation function:\n",
      "\n",
      "* `BinaryCrossentropy` is matched with `lasagne.nonlinearities.sigmoid` and used for binary classification problems\n",
      "* `CategoricalCrossentropy` is matched with `lasagne.nonlinearities.softmax` and used for multi-class classification problems\n",
      "\n",
      "Parameter initialization\n",
      "------------------------\n",
      "\n",
      "Kitchen reimplements the [lasagne initializers](http://lasagne.readthedocs.org/en/latest/modules/init.html) to support the sklearn-like initialization using the `random_state` parameter. Just instantiate `kitchen.init` classes in the `create_layers()` method instead of `lasagne.init` and pass the instaces to layer constructors.\n",
      "\n",
      "Example network - `Network1`\n",
      "============================\n",
      "\n",
      "The example below creates network with one hidden layer with 500 neurons and linear rectifier activations.\n",
      "\n",
      "The output layer uses softmax activation function, which is suitable for multi-class classification."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Network1(kitchen.Network, kitchen.SGDNesterovMomentum, kitchen.CategoricalCrossentropy, kitchen.L2Regularization):\n",
      "    def create_layers(self, X_dim, y_dim, random_state):\n",
      "        initW = kitchen.init.GlorotUniform(random_state=random_state, gain='relu')\n",
      "        initb = kitchen.init.Uniform(random_state=random_state)\n",
      "\n",
      "        input = lasagne.layers.InputLayer(shape=(None, X_dim))\n",
      "\n",
      "        hidden = lasagne.layers.DenseLayer(input,\n",
      "                                           num_units=500,\n",
      "                                           nonlinearity=lasagne.nonlinearities.rectify,\n",
      "                                           W=initW, b=initb)\n",
      "\n",
      "        output = lasagne.layers.DenseLayer(hidden,\n",
      "                                           num_units=y_dim,\n",
      "                                           nonlinearity=lasagne.nonlinearities.softmax,\n",
      "                                           W=initW, b=initb)\n",
      "\n",
      "        return input, output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "sklearn integration\n",
      "===================\n",
      "\n",
      "Kitchen is focused on the integration with sklearn so that kitchen neural networks are sklearn's classifiers and could be used in [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) and/or [`Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline).\n",
      "\n",
      "In this example, the sklearn is used to featch the 20 newsgroups dataset and transform it using the [`TfidfVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) into a TF-IDF feature vectors.\n",
      "\n",
      "The training data consists of the pair `X` and `y`, the test data `test_X` and `test_y`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.metrics import accuracy_score, roc_auc_score\n",
      "\n",
      "\n",
      "newsgroups_train = fetch_20newsgroups(subset='train')\n",
      "newsgroups_test = fetch_20newsgroups(subset='test')\n",
      "\n",
      "vectorizer = TfidfVectorizer(min_df=10)\n",
      "X = vectorizer.fit_transform(newsgroups_train.data).toarray()\n",
      "y = newsgroups_train.target\n",
      "\n",
      "test_X = vectorizer.transform(newsgroups_test.data).toarray()\n",
      "test_y = newsgroups_test.target "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Epoch and batch callbacks\n",
      "=========================\n",
      "\n",
      "It is usefull to monitor the training process. In this case we define two callback:\n",
      "\n",
      "* `epoch_callback` which is called after each epoch; it prints some time information and also the training (and test) loss and accuracy.\n",
      "* `batch_callback` which is called after each mini-batch, it just prints the number of mini-batch, used as a visual feedback during training."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def epoch_callback(stats):\n",
      "    avg_test_loss = clsf.loss(test_X, test_y)\n",
      "\n",
      "    pred_y = clsf.predict(test_X)\n",
      "    acc = accuracy_score(test_y, pred_y)\n",
      "\n",
      "    pred_y = clsf.predict(X)\n",
      "    acc_train = accuracy_score(y, pred_y)\n",
      "\n",
      "    print(\"\")\n",
      "    print(\"Epoch {}, took {}\".format(stats['epoch'], stats['t_epoch']))\n",
      "    print(\"  training loss:    \\t{:.6f}\".format(stats['avg_train_loss']))\n",
      "    print(\"  training accuracy:\\t{:.5f}\".format(acc_train))\n",
      "    print(\"  test loss:        \\t{:.6f}\".format(avg_test_loss))\n",
      "    print(\"  test accuracy:    \\t{:.5f}\".format(acc))\n",
      "\n",
      "def batch_callback(stats):\n",
      "    print stats['batch_num'],\n",
      "    sys.stdout.flush()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training the network\n",
      "====================\n",
      "\n",
      "To train the network instantiate the `Network1` class just like any other classifier from sklearn. You can specify additional parameters, e.g.:\n",
      "\n",
      "* `batch_size` - the size of the mini-batch in an SGD algorithm\n",
      "* `learning_rate` - the size of an update step\n",
      "* `alpha` - the weight of a regularization term\n",
      "* `n_epochs` - number of training epochs\n",
      "\n",
      "After creating an instance of `Network1`, just call the `fit()` method and use your training data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clsf = Network1(batch_size=128,\n",
      "               random_state=42,\n",
      "               learning_rate=0.1,\n",
      "               alpha=0.0001,\n",
      "               n_epochs=10, \n",
      "               epoch_callback=epoch_callback,\n",
      "               batch_callback=batch_callback)\n",
      "clsf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 22"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 23"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 24"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 26"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 27"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 28"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 29"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 30"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 31"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 32"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 33"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 34"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 35"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 36"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 37"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 38"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 39"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 40"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 41"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 42"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 43"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 44"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 45"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 46"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 47"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 48"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 49"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 51"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 52"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 53"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 54"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 55"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 56"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 57"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 58"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 59"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 60"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 61"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 62"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 63"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 65"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 66"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 67"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 68"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 69"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 70"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 71"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 72"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 73"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 74"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 75"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 76"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 77"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 78"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 79"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 80"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 81"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 82"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 83"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 84"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 85"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 86"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 87"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 88"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 89"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the classifier\n",
      "====================\n",
      "\n",
      "Use tha classifier in the same way as any other sklearn classifier. You can call `predict()` to predict the target classes, `predict_proba()` to predict class-probabilities or pickle the classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred_y = clsf.predict(test_X)\n",
      "acc = accuracy_score(test_y, pred_y)\n",
      "\n",
      "prob_y = clsf.predict_proba(test_X)\n",
      "\n",
      "print(\"Test accuracy: {:.5f}\".format(acc))\n",
      "print(\"Test ROC AUC for class:\")\n",
      "\n",
      "for idx, cls in enumerate(clsf.classes_):\n",
      "    auc = roc_auc_score(test_y==cls, prob_y[:, idx])\n",
      "    print(\"    {}: {:.5f}\".format(cls, auc))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}